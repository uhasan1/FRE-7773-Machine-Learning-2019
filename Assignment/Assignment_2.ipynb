{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "The purpose of this assignment is to test your understanding of Classification.  You will use the Titanic dataset and your goal is to predict whether a passenger Survives based on the passenger's features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "## General\n",
    "\n",
    "1. Use the same train  dataset as was used in the lecture.  Instructions below for where to find them.\n",
    "\n",
    "2. As usual: your grade depends on **both** the correct answer and properly presenting your process (as in the \"Recipe\" taught in class, and the Geron book Appendix B)\n",
    "\n",
    "3. You will classify whether a passenger Survives or not using Logistic Regression.\n",
    "\n",
    "4. You may use the code presented in class to **start** your assignment but I expect you to significantly enhance it.  For example: you may use my code to get you started with plotting but it is up to you to decide whether this alone suffices.\n",
    "\n",
    "5. Use 5-fold cross validation for all models.  Report the average as your result.\n",
    "\n",
    "\n",
    "## Specific goals to address\n",
    "\n",
    "1. Use a baseline model against which you will compare your models.\n",
    "    - Discuss your choice.  Is this the best baseline model to use ?\n",
    "    - Create a variable SCORE_BASELINE that contains a Python scalar value: the accuracy for your baseline model.\n",
    "2. You will conduct several experiments \n",
    "    - present a Confusion Matrix for each experiment and discuss\n",
    "    - you will create several variables per experiment that will be used for grading.\n",
    "        - The variables for experiment 1 will have suffix \"_1\". For experiment 2, they will have suffix \"_2\", etc.\n",
    "3. Experiment 1\n",
    "    - You will *extend* the results presented in the lecture\n",
    "        - use the same features\n",
    "        - use the same way of dealing with missing features\n",
    "        - be sure to treat categorical features correctly\n",
    "     \n",
    "    - Create a variable SCORE_1 that contains a Python scalar value: the accuracy for your experiment.\n",
    "    - Create a variable MISCLASSIFIED_SURVIVE_1 that contains a Python list of *at least 10* passengers\n",
    "        - the list should contain the identity of passengers that were mis-classified as Surviving.\n",
    "        - the \"identity\" of a passenger should be given as the  *row number* within the unshuffled **train** data set,\n",
    "        - The first row is considered row 0\n",
    "    - Create a variable MISCLASSIFIED_NOT_SURVIVE_1 that contains a Python list of *at least 10* passengers\n",
    "        - the list should contain the \"identity\" of passengers that were mis-classified as Not Surviving.\n",
    "        - The \"identity\" of a passenger should be given as the  *row number* within the unshuffled **train** data set, as above\n",
    "4. Experiment 2\n",
    "    - Turn Age from a continous variable to one that is assigned to buckets.\n",
    "        - You will decide the range for each bucket.  Discuss your choice\n",
    "        - Treat the buckets as categorical features\n",
    "    - Compare your prediction to the previous experiment and discuss\n",
    "    - Create variables SCORE_2, MISCLASSIFIED_SURVIVE_2, MISCLASSIFIED_NOT_SURVIVE_2 analagous to the variables in Experiment 1\n",
    "        \n",
    "The correctness part of your grade will depend on the values you assign to these variables.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra credit\n",
    "\n",
    "Create your own Logistic Regression model for the Titanic dataset given !\n",
    "- Feel free to change **anything**, e.g., features or ways to treat missing values\n",
    "- We will create a hidden test dataset\n",
    "- Students whose model accuracy (evaluated on the hidden test dataset) are in the Top 33% of the class get extra credit !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data \n",
    "You may obtain the train and test datasets from the repository using code from the following cell.\n",
    "\n",
    "**NOTE** You may need to change the NOTEBOOK_ROOT variable to point to the directory into which you've cloned the repository.  On my machine, it is `~/Notebooks/NYU`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "## NOTEBOOK_ROOT = \"~/Notebooks/NYU\"\n",
    "NOTEBOOK_ROOT = \"~/Desktop/7773 Machine Learning/ML_Spring_2019\"\n",
    "TITANIC_PATH = os.path.join( NOTEBOOK_ROOT, \"external/jack-dies\", \"data\")\n",
    "\n",
    "train_data = pd.read_csv( os.path.join(TITANIC_PATH, \"train.csv\") )\n",
    "test_data  = pd.read_csv( os.path.join(TITANIC_PATH, \"test.csv\")  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiement 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the data not possibly used in the training.\n",
    "# PassengerId, Name, Ticket are not relevant.\n",
    "# Cabin has too much missed values. It is unable to use it.\n",
    "\n",
    "# X_train\n",
    "titanic_train = train_data.drop([\"PassengerId\", \"Survived\", \"Name\", \"Ticket\", \"Cabin\"], axis=1)\n",
    "# y_train\n",
    "titanic_train_labels = train_data[\"Survived\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate the data into two part: numerical and categorical\n",
    "# numerical data of training set\n",
    "titanic_train_num = titanic_train[[\"Age\", \"SibSp\", \"Parch\", \"Fare\"]]\n",
    "# categorical data of training set\n",
    "titanic_train_cat = titanic_train[[\"Pclass\", \"Sex\", \"Embarked\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"std_scaler\", StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    ('encoder', OneHotEncoder(sparse=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = list(titanic_train_num)\n",
    "cat_attribs = list(titanic_train_cat)\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", cat_pipeline, cat_attribs)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_prepared = full_pipeline.fit_transform(titanic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_clf = LogisticRegression(solver=\"liblinear\")\n",
    "logistic_clf.fit(titanic_train_prepared, titanic_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of Experiment 1: 0.7924214488541156\n"
     ]
    }
   ],
   "source": [
    "SCORE_1 = cross_val_score(logistic_clf, titanic_train_prepared, titanic_train_labels, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "SCORE_1 =  SCORE_1.mean()\n",
    "print(\"Score of Experiment 1: {s}\".format(s=SCORE_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_predict = logistic_clf.predict(titanic_train_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_confusion_matrix = confusion_matrix(titanic_train_labels, titanic_train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn, fp, fn, tp\n",
      " 478 71 102 240\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = titanic_train_confusion_matrix.ravel()\n",
    "print(\"tn, fp, fn, tp\\n\",tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negative</th>\n",
       "      <td>478</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Positive</th>\n",
       "      <td>102</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Negative  Predicted Positive\n",
       "Actual Negative                 478                  71\n",
       "Actual Positive                 102                 240"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(titanic_train_confusion_matrix, \n",
    "             columns=[\"Predicted Negative\", \"Predicted Positive\"],\n",
    "            index=[\"Actual Negative\", \"Actual Positive\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 -> (survive) - (not survive) = misclassified survive\n",
    "# -1 -> (not survive) - (survive) = misclassified not survive\n",
    "titanic_subtract = titanic_train_predict - titanic_train_labels\n",
    "\n",
    "MISCLASSIFIED_SURVIVE_1 = list(titanic_subtract[titanic_subtract == 1].index)\n",
    "MISCLASSIFIED_NOT_SURVIVE_1 = list(titanic_subtract[titanic_subtract == -1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified Survive Passengers: \n",
      "[14, 18, 24, 34, 38, 41, 49, 64, 100, 102, 111, 113, 114, 118, 139, 140, 147, 177, 199, 205, 235, 240, 246, 264, 293, 295, 297, 312, 357, 362, 373, 374, 377, 396, 402, 404, 415, 419, 423, 452, 474, 498, 501, 502, 503, 505, 527, 534, 557, 564, 567, 578, 583, 593, 617, 634, 642, 654, 657, 680, 702, 729, 766, 767, 772, 793, 807, 816, 852, 854, 882]\n",
      "\n",
      "Misclassified Not Survive Passengers: \n",
      "[17, 21, 23, 25, 36, 55, 65, 68, 74, 78, 81, 85, 107, 125, 127, 146, 165, 183, 187, 193, 204, 207, 209, 220, 224, 226, 233, 248, 261, 267, 271, 279, 283, 286, 288, 298, 301, 328, 338, 340, 348, 390, 391, 400, 407, 414, 429, 430, 444, 447, 449, 453, 455, 460, 483, 489, 507, 509, 510, 512, 543, 547, 549, 553, 559, 569, 570, 572, 579, 587, 599, 607, 621, 622, 630, 643, 645, 647, 660, 664, 673, 690, 692, 701, 707, 709, 712, 724, 740, 744, 751, 755, 762, 788, 803, 804, 821, 828, 831, 838, 857, 869]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Misclassified Survive Passengers: \\n{p}\\n\".format(p=MISCLASSIFIED_SURVIVE_1))\n",
    "print(\"Misclassified Not Survive Passengers: \\n{p}\\n\".format(p=MISCLASSIFIED_NOT_SURVIVE_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1d6228d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data[\"Age\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Judging from the histogram of Age, we decide\n",
    "# 0-20 is the first bucket\n",
    "# 20-30 is the second bucket\n",
    "# 30-40 is the third bucket\n",
    "# 40-60 is the fourth bucket\n",
    "# above 60 is the fifth bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"AgeBucket\"] = train_data[\"Age\"] // 15 * 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_data[\"AgeBucket\"] = np.nan\n",
    "\n",
    "# for i in range(len(train_data)):\n",
    "#     if train_data.loc[i, \"Age\"] < 20:\n",
    "#         train_data.loc[i, \"AgeBucket\"] = 0\n",
    "#     if 20 <= train_data.loc[i, \"Age\"] < 30:\n",
    "#         train_data.loc[i, \"AgeBucket\"] = 1\n",
    "#     if 30 <= train_data.loc[i, \"Age\"] < 40:\n",
    "#         train_data.loc[i, \"AgeBucket\"] = 2\n",
    "#     if 40 <= train_data.loc[i, \"Age\"] < 60:\n",
    "#         train_data.loc[i, \"AgeBucket\"] = 3\n",
    "#     if train_data.loc[i, \"Age\"] >= 60:\n",
    "#         train_data.loc[i, \"AgeBucket\"] = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the data not possibly used in the training.\n",
    "# PassengerId, Name, Ticket are not relevant.\n",
    "# Cabin has too much missed values. It is unable to use it.\n",
    "# Age is replaced for AgeBucket. Drop Age.\n",
    "\n",
    "# X_train\n",
    "titanic_train = train_data.drop([\"PassengerId\", \"Survived\", \"Name\", \"Ticket\", \"Cabin\", \"Age\"], axis=1)\n",
    "# y_train\n",
    "titanic_train_labels = train_data[\"Survived\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate the data into two part: numerical and categorical\n",
    "# numerical data of training set\n",
    "titanic_train_num = titanic_train[[\"SibSp\", \"Parch\", \"Fare\"]]\n",
    "# categorical data of training set\n",
    "# AgeBucket is categorical\n",
    "titanic_train_cat = titanic_train[[\"Pclass\", \"Sex\", \"Embarked\", \"AgeBucket\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"std_scaler\", StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    ('encoder', OneHotEncoder(sparse=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = list(titanic_train_num)\n",
    "cat_attribs = list(titanic_train_cat)\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", cat_pipeline, cat_attribs)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_prepared = full_pipeline.fit_transform(titanic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_clf = LogisticRegression(solver=\"liblinear\")\n",
    "logistic_clf.fit(titanic_train_prepared, titanic_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of Experiment 2: 0.7890443143400547\n"
     ]
    }
   ],
   "source": [
    "SCORE_2 = cross_val_score(logistic_clf, titanic_train_prepared, titanic_train_labels, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "SCORE_2 =  SCORE_2.mean()\n",
    "print(\"Score of Experiment 2: {s}\".format(s=SCORE_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_predict = logistic_clf.predict(titanic_train_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_confusion_matrix = confusion_matrix(titanic_train_labels, titanic_train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn, fp, fn, tp\n",
      " 474 75 100 242\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = titanic_train_confusion_matrix.ravel()\n",
    "print(\"tn, fp, fn, tp\\n\",tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negative</th>\n",
       "      <td>474</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Positive</th>\n",
       "      <td>100</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Predicted Negative  Predicted Positive\n",
       "Actual Negative                 474                  75\n",
       "Actual Positive                 100                 242"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(titanic_train_confusion_matrix, \n",
    "             columns=[\"Predicted Negative\", \"Predicted Positive\"],\n",
    "            index=[\"Actual Negative\", \"Actual Positive\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 -> (survive) - (not survive) = misclassified survive\n",
    "# -1 -> (not survive) - (survive) = misclassified not survive\n",
    "titanic_subtract = titanic_train_predict - titanic_train_labels\n",
    "\n",
    "MISCLASSIFIED_SURVIVE_2 = list(titanic_subtract[titanic_subtract == 1].index)\n",
    "MISCLASSIFIED_NOT_SURVIVE_2 = list(titanic_subtract[titanic_subtract == -1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified Survive Passengers: \n",
      "[14, 18, 24, 30, 40, 41, 49, 64, 100, 111, 113, 114, 118, 119, 139, 140, 147, 177, 199, 205, 235, 240, 246, 254, 264, 293, 295, 297, 312, 332, 357, 362, 373, 374, 377, 396, 402, 404, 415, 419, 452, 474, 498, 501, 502, 503, 527, 534, 541, 542, 557, 564, 578, 583, 593, 617, 634, 642, 654, 657, 680, 702, 729, 766, 767, 772, 793, 799, 807, 813, 816, 852, 854, 882, 885]\n",
      "\n",
      "Misclassified Not Survive Passengers: \n",
      "[17, 21, 23, 25, 36, 55, 65, 68, 74, 81, 85, 97, 107, 125, 127, 146, 165, 183, 187, 193, 204, 207, 220, 224, 226, 248, 261, 267, 271, 279, 283, 286, 288, 298, 301, 328, 338, 340, 348, 370, 390, 391, 400, 407, 414, 429, 430, 444, 447, 449, 453, 455, 460, 483, 484, 489, 507, 509, 510, 512, 543, 547, 550, 553, 569, 570, 572, 579, 587, 599, 607, 621, 622, 643, 645, 647, 660, 664, 673, 690, 692, 701, 707, 709, 712, 724, 740, 744, 751, 755, 762, 788, 803, 804, 821, 828, 831, 838, 857, 869]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Misclassified Survive Passengers: \\n{p}\\n\".format(p=MISCLASSIFIED_SURVIVE_2))\n",
    "print(\"Misclassified Not Survive Passengers: \\n{p}\\n\".format(p=MISCLASSIFIED_NOT_SURVIVE_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
