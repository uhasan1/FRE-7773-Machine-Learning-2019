{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "The purpose of this assignment is to test your understanding of Classification.  You will use the Titanic dataset and your goal is to predict whether a passenger Survives based on the passenger's features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "## General\n",
    "\n",
    "1. Use the same train  dataset as was used in the lecture.  Instructions below for where to find them.\n",
    "\n",
    "2. As usual: your grade depends on **both** the correct answer and properly presenting your process (as in the \"Recipe\" taught in class, and the Geron book Appendix B)\n",
    "\n",
    "3. You will classify whether a passenger Survives or not using Logistic Regression.\n",
    "\n",
    "4. You may use the code presented in class to **start** your assignment but I expect you to significantly enhance it.  For example: you may use my code to get you started with plotting but it is up to you to decide whether this alone suffices.\n",
    "\n",
    "5. Use 5-fold cross validation for all models.  Report the average as your result.\n",
    "\n",
    "\n",
    "## Specific goals to address\n",
    "\n",
    "1. Use a baseline model against which you will compare your models.\n",
    "    - Discuss your choice.  Is this the best baseline model to use ?\n",
    "    - Create a variable SCORE_BASELINE that contains a Python scalar value: the accuracy for your baseline model.\n",
    "2. You will conduct several experiments \n",
    "    - present a Confusion Matrix for each experiment and discuss\n",
    "    - you will create several variables per experiment that will be used for grading.\n",
    "        - The variables for experiment 1 will have suffix \"_1\". For experiment 2, they will have suffix \"_2\", etc.\n",
    "3. Experiment 1\n",
    "    - You will *extend* the results presented in the lecture\n",
    "        - use the same features\n",
    "        - use the same way of dealing with missing features\n",
    "        - be sure to treat categorical features correctly\n",
    "     \n",
    "    - Create a variable SCORE_1 that contains a Python scalar value: the accuracy for your experiment.\n",
    "    - Create a variable MISCLASSIFIED_SURVIVE_1 that contains a Python list of *at least 10* passengers\n",
    "        - the list should contain the identity of passengers that were mis-classified as Surviving.\n",
    "        - the \"identity\" of a passenger should be given as the  *row number* within the unshuffled **train** data set,\n",
    "        - The first row is considered row 0\n",
    "    - Create a variable MISCLASSIFIED_NOT_SURVIVE_1 that contains a Python list of *at least 10* passengers\n",
    "        - the list should contain the \"identity\" of passengers that were mis-classified as Not Surviving.\n",
    "        - The \"identity\" of a passenger should be given as the  *row number* within the unshuffled **train** data set, as above\n",
    "4. Experiment 2\n",
    "    - Turn Age from a continous variable to one that is assigned to buckets.\n",
    "        - You will decide the range for each bucket.  Discuss your choice\n",
    "        - Treat the buckets as categorical features\n",
    "    - Compare your prediction to the previous experiment and discuss\n",
    "    - Create variables SCORE_2, MISCLASSIFIED_SURVIVE_2, MISCLASSIFIED_NOT_SURVIVE_2 analagous to the variables in Experiment 1\n",
    "        \n",
    "The correctness part of your grade will depend on the values you assign to these variables.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra credit\n",
    "\n",
    "Create your own Logistic Regression model for the Titanic dataset given !\n",
    "- Feel free to change **anything**, e.g., features or ways to treat missing values\n",
    "- We will create a hidden test dataset\n",
    "- Students whose model accuracy (evaluated on the hidden test dataset) are in the Top 33% of the class get extra credit !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data \n",
    "You may obtain the train and test datasets from the repository using code from the following cell.\n",
    "\n",
    "**NOTE** You may need to change the NOTEBOOK_ROOT variable to point to the directory into which you've cloned the repository.  On my machine, it is `~/Notebooks/NYU`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "## NOTEBOOK_ROOT = \"~/Notebooks/NYU\"\n",
    "NOTEBOOK_ROOT = \"~/Desktop/7773 Machine Learning/ML_Spring_2019\"\n",
    "TITANIC_PATH = os.path.join( NOTEBOOK_ROOT, \"external/jack-dies\", \"data\")\n",
    "\n",
    "train_data = pd.read_csv( os.path.join(TITANIC_PATH, \"train.csv\") )\n",
    "test_data  = pd.read_csv( os.path.join(TITANIC_PATH, \"test.csv\")  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiement 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to create some new features to help boost the accuracy\n",
    "def CreateNewFeature(Data):\n",
    "    # New Feature: Age Categories\n",
    "    df = Data\n",
    "    def AgeCat(x):\n",
    "        if x < 10:\n",
    "            return 0\n",
    "        if 10 <= x < 40:\n",
    "            return 1\n",
    "        if 40 <= x < 60:\n",
    "            return 2\n",
    "        if x >= 60:\n",
    "            return 3\n",
    "    df[\"AgeBucket\"] = df[\"Age\"].apply(AgeCat)\n",
    "    \n",
    "    # New Feature: Fare Categories\n",
    "    def FareCat(x):\n",
    "        if x < 15:\n",
    "            return 0\n",
    "        if 15 <= x <35:\n",
    "            return 1\n",
    "        if 35 <= x <90:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3    \n",
    "    df[\"FareCat\"] = df[\"Fare\"].apply(FareCat)\n",
    "    \n",
    "    # New Feature: Passenger Class & Sex\n",
    "    df[\"PclassSex\"] = df[\"Pclass\"].apply(str) + df[\"Sex\"]\n",
    "    \n",
    "    # New Feature: Family Size\n",
    "    df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\n",
    "    \n",
    "    # New Feature: Is Alone\n",
    "    def Alone(x):\n",
    "        if x == 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    df[\"IsAlone\"] = df[\"FamilySize\"].apply(Alone)\n",
    "    \n",
    "    # New Feature: Name Length\n",
    "    df[\"NameLen\"] = df[\"Name\"].apply(len)\n",
    "    \n",
    "    # New Feature: Name Prefix\n",
    "    df[\"NamePre\"] = df[\"Name\"].apply(lambda x: x.split()[1])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data = CreateNewFeature(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train\n",
    "titanic_train = new_train_data[[\"SibSp\", \"Parch\", \"Embarked\", \n",
    "                           \"PclassSex\", \"FamilySize\", \"FareCat\", \"AgeBucket\", \n",
    "                           \"IsAlone\", \"NameLen\", \"NamePre\"]]\n",
    "# y_train\n",
    "titanic_train_labels = new_train_data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate the data into two part: numerical and categorical\n",
    "\n",
    "# numerical data of training set\n",
    "titanic_train_num = titanic_train[[\"SibSp\", \"Parch\", \"FamilySize\", \"NameLen\"]]\n",
    "# categorical data of training set\n",
    "# AgeBucket is categorical\n",
    "titanic_train_cat = titanic_train[[\"Embarked\", \"PclassSex\", \"FareCat\", \"AgeBucket\", \"IsAlone\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"std_scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    ('encoder', OneHotEncoder(sparse=False))\n",
    "])\n",
    "\n",
    "num_attribs = list(titanic_train_num)\n",
    "cat_attribs = list(titanic_train_cat)\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", cat_pipeline, cat_attribs)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set transformed by all the pipeline(imputer, encoder, standard scaler)\n",
    "titanic_train_prepared = full_pipeline.fit_transform(titanic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_clf = LogisticRegression(solver=\"liblinear\")\n",
    "logistic_clf.fit(titanic_train_prepared, titanic_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8159540419187691\n"
     ]
    }
   ],
   "source": [
    "SCORE = cross_val_score(logistic_clf, titanic_train_prepared, titanic_train_labels, cv=5, scoring=\"accuracy\")\n",
    "SCORE =  SCORE.mean()\n",
    "print(\"Score: {s}\".format(s=SCORE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_predict = logistic_clf.predict(titanic_train_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_confusion_matrix = confusion_matrix(titanic_train_labels, titanic_train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                 504                  45\n",
      "Actual Positive                 106                 236\n"
     ]
    }
   ],
   "source": [
    "CONFUSION_MATRIX = pd.DataFrame(titanic_train_confusion_matrix, \n",
    "                                  columns=[\"Predicted Negative\", \"Predicted Positive\"],\n",
    "                                  index=[\"Actual Negative\", \"Actual Positive\"])\n",
    "print(\"Confusion Matrix: \\n\")\n",
    "print(CONFUSION_MATRIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_subtract = titanic_train_predict - titanic_train_labels\n",
    "# 1 suggests that (survive) - (not survive) = misclassified survive\n",
    "# -1 suggests that (not survive) - (survive) = misclassified not survive\n",
    "\n",
    "MISCLASSIFIED_SURVIVE = list(titanic_subtract[titanic_subtract == 1].index)\n",
    "MISCLASSIFIED_NOT_SURVIVE = list(titanic_subtract[titanic_subtract == -1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified Survive Passengers: Total 45\n",
      "\n",
      "[14, 18, 24, 34, 41, 49, 54, 114, 118, 139, 140, 147, 177, 199, 205, 246, 264, 297, 312, 351, 357, 373, 374, 415, 423, 452, 498, 501, 502, 505, 557, 578, 583, 617, 654, 657, 680, 702, 766, 767, 772, 799, 852, 854, 867] \n",
      "\n",
      "Misclassified Not Survive Passengers: Total 106\n",
      "\n",
      "[2, 17, 21, 23, 25, 36, 55, 65, 68, 74, 79, 81, 85, 106, 107, 125, 127, 128, 141, 146, 183, 187, 204, 207, 209, 216, 220, 224, 226, 233, 248, 261, 267, 271, 279, 283, 286, 288, 298, 301, 315, 330, 338, 376, 390, 391, 400, 414, 429, 444, 447, 449, 453, 455, 460, 483, 509, 510, 512, 543, 547, 553, 554, 569, 570, 572, 579, 587, 607, 621, 622, 630, 632, 643, 645, 649, 660, 664, 673, 677, 690, 692, 701, 707, 709, 712, 724, 740, 744, 755, 762, 780, 786, 788, 797, 802, 804, 821, 823, 828, 838, 839, 855, 857, 869, 889] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Misclassified Survive Passengers: Total {p}\\n\".format(p=len(MISCLASSIFIED_SURVIVE)))\n",
    "print(MISCLASSIFIED_SURVIVE, \"\\n\")\n",
    "print(\"Misclassified Not Survive Passengers: Total {p}\\n\".format(p=len(MISCLASSIFIED_NOT_SURVIVE)))\n",
    "print(MISCLASSIFIED_NOT_SURVIVE, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_data = CreateNewFeature(test_data)\n",
    "\n",
    "# X_test\n",
    "titanic_test = new_test_data[[\"SibSp\", \"Parch\", \"Embarked\", \n",
    "                           \"PclassSex\", \"FamilySize\", \"FareCat\", \"AgeBucket\", \n",
    "                           \"IsAlone\", \"NameLen\", \"NamePre\"]]\n",
    "\n",
    "titanic_test_prepared = full_pipeline.fit_transform(titanic_test)\n",
    "\n",
    "test_predict = logistic_clf.predict(titanic_test_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1\n",
      " 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 1 1 1 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
