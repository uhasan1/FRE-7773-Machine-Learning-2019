{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "The purpose of this assignment is to test your understanding of Classification.  You will use the Titanic dataset and your goal is to predict whether a passenger Survives based on the passenger's features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "## General\n",
    "\n",
    "1. Use the same train  dataset as was used in the lecture.  Instructions below for where to find them.\n",
    "\n",
    "2. As usual: your grade depends on **both** the correct answer and properly presenting your process (as in the \"Recipe\" taught in class, and the Geron book Appendix B)\n",
    "\n",
    "3. You will classify whether a passenger Survives or not using Logistic Regression.\n",
    "\n",
    "4. You may use the code presented in class to **start** your assignment but I expect you to significantly enhance it.  For example: you may use my code to get you started with plotting but it is up to you to decide whether this alone suffices.\n",
    "\n",
    "5. Use 5-fold cross validation for all models.  Report the average as your result.\n",
    "\n",
    "\n",
    "## Specific goals to address\n",
    "\n",
    "1. Use a baseline model against which you will compare your models.\n",
    "    - Discuss your choice.  Is this the best baseline model to use ?\n",
    "    - Create a variable SCORE_BASELINE that contains a Python scalar value: the accuracy for your baseline model.\n",
    "2. You will conduct several experiments \n",
    "    - present a Confusion Matrix for each experiment and discuss\n",
    "    - you will create several variables per experiment that will be used for grading.\n",
    "        - The variables for experiment 1 will have suffix \"_1\". For experiment 2, they will have suffix \"_2\", etc.\n",
    "3. Experiment 1\n",
    "    - You will *extend* the results presented in the lecture\n",
    "        - use the same features\n",
    "        - use the same way of dealing with missing features\n",
    "        - be sure to treat categorical features correctly\n",
    "     \n",
    "    - Create a variable SCORE_1 that contains a Python scalar value: the accuracy for your experiment.\n",
    "    - Create a variable MISCLASSIFIED_SURVIVE_1 that contains a Python list of *at least 10* passengers\n",
    "        - the list should contain the identity of passengers that were mis-classified as Surviving.\n",
    "        - the \"identity\" of a passenger should be given as the  *row number* within the unshuffled **train** data set,\n",
    "        - The first row is considered row 0\n",
    "    - Create a variable MISCLASSIFIED_NOT_SURVIVE_1 that contains a Python list of *at least 10* passengers\n",
    "        - the list should contain the \"identity\" of passengers that were mis-classified as Not Surviving.\n",
    "        - The \"identity\" of a passenger should be given as the  *row number* within the unshuffled **train** data set, as above\n",
    "4. Experiment 2\n",
    "    - Turn Age from a continous variable to one that is assigned to buckets.\n",
    "        - You will decide the range for each bucket.  Discuss your choice\n",
    "        - Treat the buckets as categorical features\n",
    "    - Compare your prediction to the previous experiment and discuss\n",
    "    - Create variables SCORE_2, MISCLASSIFIED_SURVIVE_2, MISCLASSIFIED_NOT_SURVIVE_2 analagous to the variables in Experiment 1\n",
    "        \n",
    "The correctness part of your grade will depend on the values you assign to these variables.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra credit\n",
    "\n",
    "Create your own Logistic Regression model for the Titanic dataset given !\n",
    "- Feel free to change **anything**, e.g., features or ways to treat missing values\n",
    "- We will create a hidden test dataset\n",
    "- Students whose model accuracy (evaluated on the hidden test dataset) are in the Top 33% of the class get extra credit !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data \n",
    "You may obtain the train and test datasets from the repository using code from the following cell.\n",
    "\n",
    "**NOTE** You may need to change the NOTEBOOK_ROOT variable to point to the directory into which you've cloned the repository.  On my machine, it is `~/Notebooks/NYU`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "## NOTEBOOK_ROOT = \"~/Notebooks/NYU\"\n",
    "NOTEBOOK_ROOT = \"~/Desktop/7773 Machine Learning/ML_Spring_2019\"\n",
    "TITANIC_PATH = os.path.join( NOTEBOOK_ROOT, \"external/jack-dies\", \"data\")\n",
    "\n",
    "train_data = pd.read_csv( os.path.join(TITANIC_PATH, \"train.csv\") )\n",
    "test_data  = pd.read_csv( os.path.join(TITANIC_PATH, \"test.csv\")  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:1.2em\" >\n",
    "The baseline model I use is a coin flip model. The head suggests that Survive, and the tail suggests Not-Survive. We do not use any information in the data set, and it is basically a guess about whether a specific passenger would survive or not. In the following Experiment 1 and 2, we will compare the accuracy between the coin flip game and the fine-tuned Logistic Regression Model.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the coin flip model\n",
    "def TitanicCoinFlip(X):\n",
    "    \"\"\"\n",
    "    Parameter: X: passenger data object\n",
    "    Return: y_predict: a list of predicted values\n",
    "    \"\"\"\n",
    "    y_predict = []\n",
    "    random.seed(42)\n",
    "    for i in range(len(X)):\n",
    "        # random number generated > 0.5 represents Survive\n",
    "        if random.random() > 0.5:\n",
    "            y_predict.append(1)\n",
    "        else:\n",
    "        # random number generated < 0.5 represents Survive\n",
    "            y_predict.append(0)\n",
    "    \n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Baseline:  0.5050505050505051\n"
     ]
    }
   ],
   "source": [
    "# the predicted values\n",
    "titanic_y_predict = np.array(TitanicCoinFlip(train_data))\n",
    "# the true values\n",
    "titanic_train_labels = train_data[\"Survived\"]\n",
    "\n",
    "# the Baseline Score of the Coin Flip Model\n",
    "SCORE_BASELINE = accuracy_score(titanic_train_labels.values, titanic_y_predict)\n",
    "print(\"Score Baseline: \", SCORE_BASELINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:1.2em\" >\n",
    "The score baseline shows that there is about 50% chance that the model will make a correct prediction on whether a specific passenger would survive or not.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiement 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the data not possibly used in the training.\n",
    "# PassengerId, Name, Ticket are not relevant.\n",
    "# Cabin has too much missed values. It is unable to use it.\n",
    "\n",
    "# X_train\n",
    "titanic_train = train_data.drop([\"PassengerId\", \"Survived\", \"Name\", \"Ticket\", \"Cabin\"], axis=1)\n",
    "# y_train\n",
    "titanic_train_labels = train_data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate the data into two part: numerical and categorical\n",
    "\n",
    "# numerical data of training set\n",
    "titanic_train_num = titanic_train[[\"Age\", \"SibSp\", \"Parch\", \"Fare\"]]\n",
    "# categorical data of training set\n",
    "titanic_train_cat = titanic_train[[\"Pclass\", \"Sex\", \"Embarked\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"std_scaler\", StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    ('encoder', OneHotEncoder(sparse=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = list(titanic_train_num)\n",
    "cat_attribs = list(titanic_train_cat)\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", cat_pipeline, cat_attribs)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set transformed by all the pipeline(imputer, encoder, standard scaler)\n",
    "titanic_train_prepared = full_pipeline.fit_transform(titanic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_clf = LogisticRegression(solver=\"liblinear\")\n",
    "logistic_clf.fit(titanic_train_prepared, titanic_train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:1.2em\" >\n",
    "The score of accuracy of Experiment 1 shows below.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of Experiment 1: 0.7924214488541156\n"
     ]
    }
   ],
   "source": [
    "SCORE_1 = cross_val_score(logistic_clf, titanic_train_prepared, titanic_train_labels, cv=5, scoring=\"accuracy\")\n",
    "SCORE_1 =  SCORE_1.mean()\n",
    "print(\"Score of Experiment 1: {s}\".format(s=SCORE_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_predict = logistic_clf.predict(titanic_train_prepared)\n",
    "titanic_train_confusion_matrix = confusion_matrix(titanic_train_labels, titanic_train_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:1.2em\" >\n",
    "The Confusion Matrix of Experiment 1 shows below.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Experiment 1: \n",
      "\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                 478                  71\n",
      "Actual Positive                 102                 240\n"
     ]
    }
   ],
   "source": [
    "CONFUSION_MATRIX_1 = pd.DataFrame(titanic_train_confusion_matrix, \n",
    "                                  columns=[\"Predicted Negative\", \"Predicted Positive\"],\n",
    "                                  index=[\"Actual Negative\", \"Actual Positive\"])\n",
    "print(\"Confusion Matrix of Experiment 1: \\n\")\n",
    "print(CONFUSION_MATRIX_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_subtract = titanic_train_predict - titanic_train_labels\n",
    "# 1 suggests that (survive) - (not survive) = misclassified survive\n",
    "# -1 suggests that (not survive) - (survive) = misclassified not survive\n",
    "\n",
    "MISCLASSIFIED_SURVIVE_1 = list(titanic_subtract[titanic_subtract == 1].index)\n",
    "MISCLASSIFIED_NOT_SURVIVE_1 = list(titanic_subtract[titanic_subtract == -1].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:1.2em\" >\n",
    "Lastly, the misclassification outcome of Experiment 1 shows below.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified Survive Passengers: Total 71\n",
      "\n",
      "[14, 18, 24, 34, 38, 41, 49, 64, 100, 102, 111, 113, 114, 118, 139, 140, 147, 177, 199, 205, 235, 240, 246, 264, 293, 295, 297, 312, 357, 362, 373, 374, 377, 396, 402, 404, 415, 419, 423, 452, 474, 498, 501, 502, 503, 505, 527, 534, 557, 564, 567, 578, 583, 593, 617, 634, 642, 654, 657, 680, 702, 729, 766, 767, 772, 793, 807, 816, 852, 854, 882] \n",
      "\n",
      "Misclassified Not Survive Passengers: Total 102\n",
      "\n",
      "[17, 21, 23, 25, 36, 55, 65, 68, 74, 78, 81, 85, 107, 125, 127, 146, 165, 183, 187, 193, 204, 207, 209, 220, 224, 226, 233, 248, 261, 267, 271, 279, 283, 286, 288, 298, 301, 328, 338, 340, 348, 390, 391, 400, 407, 414, 429, 430, 444, 447, 449, 453, 455, 460, 483, 489, 507, 509, 510, 512, 543, 547, 549, 553, 559, 569, 570, 572, 579, 587, 599, 607, 621, 622, 630, 643, 645, 647, 660, 664, 673, 690, 692, 701, 707, 709, 712, 724, 740, 744, 751, 755, 762, 788, 803, 804, 821, 828, 831, 838, 857, 869] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Misclassified Survive Passengers: Total {p}\\n\".format(p=len(MISCLASSIFIED_SURVIVE_1)))\n",
    "print(MISCLASSIFIED_SURVIVE_1, \"\\n\")\n",
    "print(\"Misclassified Not Survive Passengers: Total {p}\\n\".format(p=len(MISCLASSIFIED_NOT_SURVIVE_1)))\n",
    "print(MISCLASSIFIED_NOT_SURVIVE_1, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:1.2em\" >\n",
    "I plot the histograms of Age of the Survived and the Not-Survived below.\n",
    "The difference between the two histograms shows that the children 10 years old or younger have a higher probability to survive and the passengers older than 60 have a higher probility to die. Thus, I decide to make that 0-10 is the first bucket, 10-40 is the second bucket, 40-60 is the third bucket, and above 60 is the fourth bucket.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a295c43c8>"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(7,5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax = train_data[train_data[\"Survived\"] == 1][\"Age\"].hist(bins=80, color=\"red\", alpha=0.7, label=\"Survive\")\n",
    "ax = train_data[train_data[\"Survived\"] == 0][\"Age\"].hist(bins=80, color=\"blue\", alpha=0.5, label=\"Not Survive\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AgeCat(x):\n",
    "    if x < 10:\n",
    "        return 0\n",
    "    if 10 <= x < 40:\n",
    "        return 1\n",
    "    if 40 <= x < 60:\n",
    "        return 2\n",
    "    if x >= 60:\n",
    "        return 3\n",
    "\n",
    "train_data[\"AgeBucket\"] = train_data[\"Age\"].apply(AgeCat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the data not possibly used in the training.\n",
    "# PassengerId, Name, Ticket are not relevant.\n",
    "# Cabin has too much missed values. It is unable to use it.\n",
    "# Age is replaced for AgeBucket. Drop Age.\n",
    "\n",
    "# X_train\n",
    "titanic_train = train_data.drop([\"PassengerId\", \"Survived\", \"Name\", \"Ticket\", \"Cabin\", \"Age\"], axis=1)\n",
    "# y_train\n",
    "titanic_train_labels = train_data[\"Survived\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate the data into two part: numerical and categorical\n",
    "\n",
    "# numerical data of training set\n",
    "titanic_train_num = titanic_train[[\"SibSp\", \"Parch\", \"Fare\"]]\n",
    "# categorical data of training set\n",
    "# AgeBucket is categorical\n",
    "titanic_train_cat = titanic_train[[\"Pclass\", \"Sex\", \"Embarked\", \"AgeBucket\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = list(titanic_train_num)\n",
    "cat_attribs = list(titanic_train_cat)\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", cat_pipeline, cat_attribs)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set transformed by all the pipeline(imputer, encoder, standard scaler)\n",
    "titanic_train_prepared = full_pipeline.fit_transform(titanic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_clf = LogisticRegression(solver=\"liblinear\")\n",
    "logistic_clf.fit(titanic_train_prepared, titanic_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of Experiment 2: 0.8047307828570031\n"
     ]
    }
   ],
   "source": [
    "SCORE_2 = cross_val_score(logistic_clf, titanic_train_prepared, titanic_train_labels, cv=5, scoring=\"accuracy\")\n",
    "SCORE_2 =  SCORE_2.mean()\n",
    "print(\"Score of Experiment 2: {s}\".format(s=SCORE_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:1.2em\" >\n",
    "The score of Experiment 2 shows a higher accuracy than Experiment 1. Thus, the age buckets we make did help boost the accuracy of prediction. An effective classification and simplification of some features would help the machine learning algorithm generate a more precise outcome.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_predict = logistic_clf.predict(titanic_train_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_confusion_matrix = confusion_matrix(titanic_train_labels, titanic_train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Experiment 2: \n",
      "\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                 479                  70\n",
      "Actual Positive                  96                 246\n"
     ]
    }
   ],
   "source": [
    "CONFUSION_MATRIX_2 = pd.DataFrame(titanic_train_confusion_matrix, \n",
    "                                  columns=[\"Predicted Negative\", \"Predicted Positive\"],\n",
    "                                  index=[\"Actual Negative\", \"Actual Positive\"])\n",
    "print(\"Confusion Matrix of Experiment 2: \\n\")\n",
    "print(CONFUSION_MATRIX_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_subtract = titanic_train_predict - titanic_train_labels\n",
    "# 1 suggests that (survive) - (not survive) = misclassified survive\n",
    "# -1 suggests that (not survive) - (survive) = misclassified not survive\n",
    "\n",
    "MISCLASSIFIED_SURVIVE_2 = list(titanic_subtract[titanic_subtract == 1].index)\n",
    "MISCLASSIFIED_NOT_SURVIVE_2 = list(titanic_subtract[titanic_subtract == -1].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:1.2em\" >\n",
    "Lastly, the misclassification outcome of Experiment 2 shows below.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified Survive Passengers: Total 70\n",
      "\n",
      "[14, 18, 24, 41, 49, 64, 100, 111, 113, 114, 118, 119, 139, 140, 147, 177, 199, 205, 235, 240, 246, 264, 276, 293, 295, 297, 312, 357, 362, 373, 374, 377, 396, 402, 404, 415, 419, 452, 474, 498, 501, 502, 503, 505, 527, 534, 541, 557, 564, 578, 583, 593, 617, 634, 642, 654, 657, 680, 702, 729, 766, 767, 772, 793, 807, 813, 816, 852, 854, 882] \n",
      "\n",
      "Misclassified Not Survive Passengers: Total 96\n",
      "\n",
      "[17, 21, 23, 25, 36, 55, 65, 68, 74, 81, 85, 107, 125, 127, 146, 165, 183, 187, 204, 207, 209, 220, 224, 226, 248, 261, 267, 271, 279, 283, 286, 288, 298, 301, 328, 338, 348, 370, 390, 391, 400, 414, 429, 430, 444, 447, 449, 453, 455, 460, 483, 484, 489, 507, 509, 510, 512, 543, 547, 553, 569, 570, 572, 579, 587, 599, 607, 621, 622, 630, 643, 645, 647, 660, 664, 673, 690, 692, 701, 707, 709, 712, 724, 740, 744, 751, 762, 788, 802, 803, 804, 821, 828, 838, 857, 869] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Misclassified Survive Passengers: Total {p}\\n\".format(p=len(MISCLASSIFIED_SURVIVE_2)))\n",
    "print(MISCLASSIFIED_SURVIVE_2, \"\\n\")\n",
    "print(\"Misclassified Not Survive Passengers: Total {p}\\n\".format(p=len(MISCLASSIFIED_NOT_SURVIVE_2)))\n",
    "print(MISCLASSIFIED_NOT_SURVIVE_2, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:1.2em\" >\n",
    "Firstly, we try to do feature engineering, by creating some new features to help boost the accuracy.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to create some new features to help boost the accuracy\n",
    "def CreateNewFeature(Data):\n",
    "    # New Feature: Age Categories\n",
    "    df = Data\n",
    "    def AgeCat(x):\n",
    "        if x < 10:\n",
    "            return 0\n",
    "        if 10 <= x < 40:\n",
    "            return 1\n",
    "        if 40 <= x < 60:\n",
    "            return 2\n",
    "        if x >= 60:\n",
    "            return 3\n",
    "    df[\"AgeBucket\"] = df[\"Age\"].apply(AgeCat)\n",
    "    \n",
    "    # New Feature: Fare Categories\n",
    "    def FareCat(x):\n",
    "        if x < 15:\n",
    "            return 0\n",
    "        if 15 <= x <35:\n",
    "            return 1\n",
    "        if 35 <= x <90:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3    \n",
    "    df[\"FareCat\"] = df[\"Fare\"].apply(FareCat)\n",
    "    \n",
    "    # New Feature: Passenger Class & Sex\n",
    "    df[\"PclassSex\"] = df[\"Pclass\"].apply(str) + df[\"Sex\"]\n",
    "    \n",
    "    # New Feature: Family Size\n",
    "    df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\n",
    "    \n",
    "    # New Feature: Is Alone\n",
    "    def Alone(x):\n",
    "        if x == 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    df[\"IsAlone\"] = df[\"FamilySize\"].apply(Alone)\n",
    "    \n",
    "    # New Feature: Name Length\n",
    "    df[\"NameLen\"] = df[\"Name\"].apply(len)\n",
    "    \n",
    "    # New Feature: Name Prefix\n",
    "    df[\"NamePre\"] = df[\"Name\"].apply(lambda x: x.split()[1])\n",
    "    # Simplify the Name Prefix Categories\n",
    "    def NamePreCat(x):\n",
    "        if x not in [\"Mr.\", \"Miss.\", \"Mrs.\", \"Masters.\"]:\n",
    "            return \"Others\"\n",
    "        else:\n",
    "            return x\n",
    "    df[\"NamePre\"] = df[\"NamePre\"].apply(NamePreCat)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data = CreateNewFeature(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train\n",
    "titanic_train = new_train_data[[\"SibSp\", \"Parch\", \"Embarked\", \"Pclass\", \"Sex\",\n",
    "                           \"PclassSex\", \"FamilySize\", \"FareCat\", \"AgeBucket\", \n",
    "                           \"IsAlone\", \"NameLen\", \"NamePre\"]]\n",
    "# y_train\n",
    "titanic_train_labels = new_train_data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate the data into two part: numerical and categorical\n",
    "\n",
    "# numerical data of training set\n",
    "titanic_train_num = titanic_train[[\"SibSp\", \"Parch\", \"FamilySize\", \"NameLen\"]]\n",
    "# categorical data of training set\n",
    "# AgeBucket is categorical\n",
    "titanic_train_cat = titanic_train[[\"Embarked\", \"PclassSex\", \"FareCat\", \"AgeBucket\", \"IsAlone\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"std_scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    ('encoder', OneHotEncoder(sparse=False))\n",
    "])\n",
    "\n",
    "num_attribs = list(titanic_train_num)\n",
    "cat_attribs = list(titanic_train_cat)\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", cat_pipeline, cat_attribs)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set transformed by all the pipeline(imputer, encoder, standard scaler)\n",
    "titanic_train_prepared = full_pipeline.fit_transform(titanic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_clf = LogisticRegression(solver=\"liblinear\")\n",
    "logistic_clf.fit(titanic_train_prepared, titanic_train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:1.2em\" >\n",
    "Using 5-fold Cross Validation, we calculate the accuracy of the new model below. By doing feature engineering and creating new features, the model does make more accurate prediction.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8159540419187691\n"
     ]
    }
   ],
   "source": [
    "SCORE = cross_val_score(logistic_clf, titanic_train_prepared, titanic_train_labels, cv=5, scoring=\"accuracy\")\n",
    "SCORE =  SCORE.mean()\n",
    "print(\"Score: {s}\".format(s=SCORE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_predict = logistic_clf.predict(titanic_train_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_confusion_matrix = confusion_matrix(titanic_train_labels, titanic_train_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:1.2em\" >\n",
    "The Confusion Matrix of this new model shows below.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                 504                  45\n",
      "Actual Positive                 106                 236\n"
     ]
    }
   ],
   "source": [
    "CONFUSION_MATRIX = pd.DataFrame(titanic_train_confusion_matrix, \n",
    "                                  columns=[\"Predicted Negative\", \"Predicted Positive\"],\n",
    "                                  index=[\"Actual Negative\", \"Actual Positive\"])\n",
    "print(\"Confusion Matrix: \\n\")\n",
    "print(CONFUSION_MATRIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:1.2em\" >\n",
    "Lastly, all the predicted values of the test data show below.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1\n",
      " 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 1 1 1 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "new_test_data = CreateNewFeature(test_data)\n",
    "\n",
    "# X_test\n",
    "titanic_test = new_test_data[[\"SibSp\", \"Parch\", \"Embarked\", \n",
    "                           \"PclassSex\", \"FamilySize\", \"FareCat\", \"AgeBucket\", \n",
    "                           \"IsAlone\", \"NameLen\", \"NamePre\"]]\n",
    "\n",
    "titanic_test_prepared = full_pipeline.fit_transform(titanic_test)\n",
    "\n",
    "test_predict = logistic_clf.predict(titanic_test_prepared)\n",
    "print(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
