{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Network Examples\n",
    "**Make sure you have activated the correct python envorinment**\n",
    "\n",
    "+ Using keras API and MNIST data\n",
    "+ Using graphviz for visualization of the network\n",
    "\n",
    "### Graphviz installation\n",
    "1. Download and install from [graphviz site](https://graphviz.gitlab.io/download)\n",
    "2. Put the executable on the system path\n",
    "3. Install the pydot python package using command  \n",
    "   `conda install -c conda-forge pydot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "np.random.seed(42)\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Input, Dense, Activation\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "MNIST is a dataset of 60,000 28x28 grayscale images of handwritten digits, along with a test set of 10,000 images.\n",
    "\n",
    "Load the MNIST data using keras. The first time the data are downloaded and cached.  \n",
    "Subsequent times the data are loaded from the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True values: [7 3 2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the date and split into training/testing sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# plot a few digits and print the true values\n",
    "idigits = [53643, 4543, 5]\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "for i in range(len(idigits)):\n",
    "    ax = fig.add_subplot(1, len(idigits), i + 1)\n",
    "    ax.imshow(x_train[idigits[i]], cmap = plt.cm.binary, interpolation=\"nearest\")\n",
    "    ax.axis(\"off\")\n",
    "print('True values: {}'.format(y_train[idigits]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape, cast, normalize inputs\n",
    "* Reshape the data: 28x28 -> 784  \n",
    "* Cast the values int8 -> float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "n_train = len(x_train)  # 60000\n",
    "n_test = len(x_test)  # 60000\n",
    "input_dim = 28 * 28\n",
    "\n",
    "x_train = x_train.reshape(n_train, input_dim)\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.reshape(n_test, input_dim)\n",
    "x_test = x_test.astype(np.float32)\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the target values vector to binary class matrix\n",
    "y_train is a vector of size 60,000.  \n",
    "It gets mapped to a 60,000 x 10 matrix of 0s and 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets before: \n",
      "[5 0 4 1 9]\n",
      "Targets after: \n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Targets before: \\n{}\".format(y_train[:5]))\n",
    "ybm_train = to_categorical(y_train, n_classes)\n",
    "ybm_test = to_categorical(y_test, n_classes)\n",
    "print(\"Targets after: \\n{}\".format(ybm_train[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the model\n",
    "This is a shallow, dense network.  \n",
    "We use one output layer with softmax activation.  \n",
    "Softmax is also used in multi-class logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn1 = Sequential()\n",
    "nn1.add(Dense(n_classes, input_dim=input_dim, activation='softmax'))\n",
    "nn1.summary()\n",
    "plot_model(nn1, show_shapes = True, to_file='nn1.png')\n",
    "\n",
    "# the number of parameters is: n_classes x (input_dim + 1)\n",
    "# each node has its own bias (therefore +1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single-layer DNN\n",
      "------------------------\n",
      "Test loss score: 0.3232\n",
      "Test accuracy:   0.9112\n"
     ]
    }
   ],
   "source": [
    "nn1.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 100\n",
    "n_epochs = 20\n",
    "nn1_hist = nn1.fit(x_train, ybm_train, batch_size=batch_size, epochs=n_epochs, verbose=0)\n",
    "val_score = nn1.evaluate(x_test, ybm_test, verbose=0)\n",
    "\n",
    "print('Single-layer DNN')\n",
    "print('------------------------')\n",
    "print('Test loss score: {0:.4f}'.format(val_score[0]))\n",
    "print('Test accuracy:   {0:.4f}'.format(val_score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a deeper network \n",
    "\n",
    "Two hidden layers, with 3\\*n_classes and 2\\*n_classes units.  \n",
    "The final output layer has n_classes units.  \n",
    "We build the model using the functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "hidden_1 (Dense)             (None, 30)                23550     \n",
      "_________________________________________________________________\n",
      "hidden_2 (Dense)             (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 24,380\n",
      "Trainable params: 24,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# construct\n",
    "\n",
    "inputs = Input(shape=(input_dim,), name='inputs')\n",
    "x = Dense(3*n_classes, input_dim=input_dim, activation='relu', name='hidden_1')(inputs)\n",
    "x = Dense(2*n_classes, input_dim=input_dim, activation='relu', name='hidden_2')(x)\n",
    "outputs = Dense(n_classes, activation='softmax', name='output')(x)\n",
    "\n",
    "nn3 = Model(inputs=inputs, outputs=outputs)\n",
    "nn3.summary()\n",
    "plot_model(nn3, show_shapes = True, to_file='nn3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-Layer DNN\n",
      "------------------------\n",
      "Test loss score: 0.1844\n",
      "Test accuracy:   0.9457\n"
     ]
    }
   ],
   "source": [
    "# compile, fit and evaluate\n",
    "nn3.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "batch_size3 = 100\n",
    "n_epochs3 = 20\n",
    "nn3_hist = nn3.fit(x_train, ybm_train, batch_size=batch_size3, epochs=n_epochs3, verbose=0)\n",
    "val_score = nn3.evaluate(x_test, ybm_test, verbose=0)\n",
    "\n",
    "print('3-Layer DNN')\n",
    "print('------------------------')\n",
    "print('Test loss score: {0:.4f}'.format(val_score[0]))\n",
    "print('Test accuracy:   {0:.4f}'.format(val_score[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-layer DNN predictions and true values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7, 2, 1, 0, 4, 1, 4, 9, 6, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn3_pred = nn3.predict(x_test[:20])\n",
    "nn3_ypred = np.argmax(nn3_pred, axis=1)\n",
    "\n",
    "print('3-layer DNN predictions and true values')\n",
    "display(nn3_ypred.tolist())\n",
    "display(y_test[:20].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression \n",
    "\n",
    "We fit a multiclass logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1e-05, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='multinomial',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "lgm = LogisticRegression(C=1e-5, multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "print(lgm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1e-05, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgm.fit(x_train,  y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "------------------------\n",
      "Test accuracy:   0.7482\n"
     ]
    }
   ],
   "source": [
    "y_pred = lgm.predict(x_test)\n",
    "lg_acc = accuracy_score(y_test, y_pred)\n",
    "print('Logistic Regression')\n",
    "print('------------------------')\n",
    "print('Test accuracy:   {0:.4f}'.format(lg_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression predictions and true values\n",
      "[7, 2, 1, 0, 4, 1, 4, 9, 6, 7, 0, 0, 9, 0, 1, 3, 9, 7, 3, 4]\n",
      "[7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "print('Logistic regression predictions and true values')\n",
    "print(y_pred[:20].tolist())\n",
    "print(y_test[:20].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
